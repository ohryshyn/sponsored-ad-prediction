{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 8455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_skip = ['raw_text', 'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_data = pd.concat([pd.read_csv(csv, lineterminator='\\n', usecols=lambda x: x not in cols_to_skip)\n",
    "               for csv in glob.glob('../data/csv/*.csv')], ignore_index=True)\n",
    "df_file_labels = pd.read_csv('../data/html_targets.csv')\n",
    "df = df_html_data.merge(df_file_labels, left_on='filename', right_on='file')\n",
    "df = df.drop(['file', 'filename'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english') + \\\n",
    "                 stopwords.words('french') + \\\n",
    "                 stopwords.words('german') + \\\n",
    "                 stopwords.words('spanish')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = WordNetLemmatizer()\n",
    "text_transformer = TfidfVectorizer(max_features=250, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].fillna('')\n",
    "df['title'] = df['title'].map(lambda x: x.lower())\n",
    "df['title'] = df['title'].map(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['title'] = df['title'].map(lambda x: re.sub(r'\\d+', '', x))\n",
    "df['title'] = df['title'].map(lambda x: [lemmer.lemmatize(word) for word in x.split() if word not in stop_words])\n",
    "df['title'] = df['title'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = text_transformer.fit_transform(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(df_text.toarray(), columns=text_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['sponsored'], axis=1)\n",
    "y = df['sponsored']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"clf\", DummyEstimator())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__class_weight=balanced, clf__colsample_bytree=1.2557340860902042, clf__gamma=0.14883575458027015, clf__learning_rate=0.030226971886820067, clf__max_depth=3, clf__min_child_weight=1, clf__subsample=1.404962871504809; total time=  15.9s\n",
      "[CV] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__class_weight=balanced, clf__colsample_bytree=1.2557340860902042, clf__gamma=0.14883575458027015, clf__learning_rate=0.030226971886820067, clf__max_depth=3, clf__min_child_weight=1, clf__subsample=1.404962871504809; total time=  17.7s\n",
      "[CV] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__class_weight=balanced, clf__colsample_bytree=1.248176745229302, clf__gamma=0.14883575458027015, clf__learning_rate=0.030226971886820067, clf__max_depth=3, clf__min_child_weight=1, clf__subsample=1.404962871504809; total time=  16.1s\n",
      "[CV] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__class_weight=balanced, clf__colsample_bytree=1.248176745229302, clf__gamma=0.14883575458027015, clf__learning_rate=0.030226971886820067, clf__max_depth=3, clf__min_child_weight=1, clf__subsample=1.404962871504809; total time=  15.5s\n",
      "[21:19:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "CPU times: user 9min 9s, sys: 12.8 s, total: 9min 22s\n",
      "Wall time: 4min 38s\n",
      "{'clf': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              class_weight='balanced', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.938933521522551,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0.14883575458027015,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.20674232396227338,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, ...), 'clf__class_weight': 'balanced', 'clf__colsample_bytree': 0.938933521522551, 'clf__gamma': 0.14883575458027015, 'clf__learning_rate': 0.20674232396227338, 'clf__max_depth': 3, 'clf__min_child_weight': 1, 'clf__subsample': 0.9762407178762023}\n",
      "0.5659498419360698\n",
      "0.5580774906511355\n"
     ]
    }
   ],
   "source": [
    "param_distributions = [{\n",
    "    'clf': [RandomForestClassifier()],\n",
    "    'clf__n_estimators': randint(100, 300),\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__min_samples_split': randint(5, 10),\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_samples': uniform(0.1, 0.9)\n",
    "},\n",
    "{\n",
    "    'clf': [CatBoostClassifier()],\n",
    "    'clf__depth': randint(4, 10),\n",
    "    'clf__learning_rate': uniform(0.1, 0.4),\n",
    "    'clf__l2_leaf_reg': randint(1, 10),\n",
    "    'clf__iterations': randint(200, 400)\n",
    "},\n",
    "{\n",
    "    'clf': [XGBClassifier()],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_depth': randint(3, 10),\n",
    "    'clf__learning_rate': uniform(0.2, 0.1),\n",
    "    'clf__subsample': uniform(0.75, 0.25),\n",
    "    'clf__colsample_bytree': uniform(0.75, 0.25),\n",
    "    'clf__gamma': uniform(0, 0.5),\n",
    "    'clf__min_child_weight': randint(1, 10)\n",
    "}\n",
    "]\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe,\n",
    "                                   param_distributions,\n",
    "                                   n_iter=100,\n",
    "                                   cv=10,\n",
    "                                   verbose=2,\n",
    "                                   random_state=SEED,\n",
    "                                   scoring='f1_macro',\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "%time random_search.fit(X_train, y_train) \n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)\n",
    "print(random_search.score(X_test, y_test))  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
